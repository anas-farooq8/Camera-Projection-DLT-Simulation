{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive figures in Jupyter Notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.linalg import rq\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotation_matrix(yaw, pitch, roll):\n",
    "    # Convert angles to radians\n",
    "    yaw = np.radians(yaw)\n",
    "    pitch = np.radians(pitch)\n",
    "    roll = np.radians(roll)\n",
    "    # Yaw matrix around Y axis\n",
    "    R_yaw = np.array([\n",
    "        [np.cos(yaw), 0, np.sin(yaw)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(yaw), 0, np.cos(yaw)]\n",
    "    ])\n",
    "    # Pitch matrix around X axis\n",
    "    R_pitch = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(pitch), -np.sin(pitch)],\n",
    "        [0, np.sin(pitch), np.cos(pitch)]\n",
    "    ])\n",
    "    # Roll matrix around Z axis\n",
    "    R_roll = np.array([\n",
    "        [np.cos(roll), -np.sin(roll), 0],\n",
    "        [np.sin(roll), np.cos(roll), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # Combine the matrices\n",
    "    R_combined = R_roll.dot(R_pitch).dot(R_yaw)\n",
    "    return R_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGTCameraParameters(focal_length_x, focal_length_y, principal_point_x, principal_point_y, R, camera_translation_vector_from_world_origin):\n",
    "    # Construct a 4x4 extrinsic matrix\n",
    "    extrinsic_matrix = np.eye(4)\n",
    "    extrinsic_matrix[:3, :3] = R  # Rotation\n",
    "    extrinsic_matrix[:3, 3] = -R @ camera_translation_vector_from_world_origin  # Translation\n",
    "    \n",
    "    # Construct the intrinsic matrix (3x4)\n",
    "    K = np.array([[focal_length_x, 0, principal_point_x, 0],\n",
    "                  [0, focal_length_y, principal_point_y, 0],\n",
    "                  [0, 0, 1, 0]])\n",
    "    \n",
    "    # Camera projection matrix P = K * [R|t]\n",
    "    P = np.dot(K, extrinsic_matrix)\n",
    "    \n",
    "    print(\"\\nCamera Center in World Coordinates:\")\n",
    "    print(camera_translation_vector_from_world_origin)\n",
    "    print(\"\\nCamera Translation Vector (t):\")\n",
    "    print(extrinsic_matrix[:3, 3])\n",
    "    print(\"\\nCamera Rotation Matrix (R):\")\n",
    "    print(R)\n",
    "    print(\"\\nExtrinsic Matrix [R|t]:\")\n",
    "    print(extrinsic_matrix)\n",
    "    print(\"\\nIntrinsic Matrix (K):\")\n",
    "    print(K)\n",
    "    print(\"\\nCamera Projection Matrix (P):\")\n",
    "    print(P)\n",
    "\n",
    "    return P, extrinsic_matrix, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_world_to_camera(points_3d, P, image_width, image_height):\n",
    "    # Convert 3D points to homogeneous coordinates\n",
    "    points_3d_homogeneous = np.column_stack((points_3d, np.ones((points_3d.shape[0], 1))))\n",
    "    # Project the points using P\n",
    "    points_2d_homogeneous = np.dot(P, points_3d_homogeneous.T).T\n",
    "    # Normalize homogeneous coordinates\n",
    "    points_2d_normalized = points_2d_homogeneous[:, :2] / points_2d_homogeneous[:, 2:]\n",
    "    # Check if points are within the image boundaries (not used for error computation)\n",
    "    points_inside_frame = np.logical_and.reduce((\n",
    "        points_2d_normalized[:, 0] >= 0,\n",
    "        points_2d_normalized[:, 0] <= image_width,  # image width\n",
    "        points_2d_normalized[:, 1] >= 0,\n",
    "        points_2d_normalized[:, 1] <= image_height   # image height\n",
    "    ))\n",
    "    return points_2d_normalized, points_inside_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWorldPoints(ax, points, rotation_matrix, camera_origin):\n",
    "    num_points = len(points)\n",
    "    # Pre-generate(fix) colors for consistency\n",
    "    np.random.seed(0)\n",
    "    colors = np.random.rand(num_points, 3)\n",
    "    for i in range(num_points):\n",
    "        ax.scatter(points[i, 0], points[i, 1], points[i, 2], c=[colors[i]], marker='o', s=50)\n",
    "        ax.text(points[i, 0], points[i, 1], points[i, 2], f'{i+1}', color='black', fontsize=10)\n",
    "    \n",
    "    # Plot a red cross at the world origin\n",
    "    ax.plot([0], [0], [0], marker='x', markersize=10, color='red')\n",
    "    \n",
    "    # Plot world coordinate axes\n",
    "    world_axes_length = 1.0\n",
    "    ax.plot([0, world_axes_length], [0, 0], [0, 0], color='green', label='World X')\n",
    "    ax.plot([0, 0], [0, world_axes_length], [0, 0], color='orange', label='World Y')\n",
    "    ax.plot([0, 0], [0, 0], [0, 3], color='purple', label='World Z')\n",
    "    \n",
    "    # Label the world axes\n",
    "    ax.text(world_axes_length, 0, 0, 'X', color='green', fontsize=12)\n",
    "    ax.text(0, world_axes_length, 0, 'Y', color='orange', fontsize=12)\n",
    "    ax.text(0, 0, 3, 'Z', color='purple', fontsize=12)\n",
    "    \n",
    "    # Plot the camera origin and coordinate axes\n",
    "    ax.plot([camera_origin[0]], [camera_origin[1]], [camera_origin[2]], marker='x', markersize=10, color='blue')\n",
    "    camera_axes_length = 1.0\n",
    "    camera_x_axis = rotation_matrix[:, 0] * camera_axes_length + camera_origin\n",
    "    camera_y_axis = rotation_matrix[:, 1] * camera_axes_length + camera_origin\n",
    "    camera_z_axis = rotation_matrix[:, 2] * 3 + camera_origin\n",
    "    ax.plot([camera_origin[0], camera_x_axis[0]], [camera_origin[1], camera_x_axis[1]], [camera_origin[2], camera_x_axis[2]], color='blue', label='Camera X')\n",
    "    ax.plot([camera_origin[0], camera_y_axis[0]], [camera_origin[1], camera_y_axis[1]], [camera_origin[2], camera_y_axis[2]], color='cyan', label='Camera Y')\n",
    "    ax.plot([camera_origin[0], camera_z_axis[0]], [camera_origin[1], camera_z_axis[1]], [camera_origin[2], camera_z_axis[2]], color='magenta', label='Camera Z')\n",
    "    ax.text(camera_x_axis[0], camera_x_axis[1], camera_x_axis[2], 'X', color='blue', fontsize=12)\n",
    "    ax.text(camera_y_axis[0], camera_y_axis[1], camera_y_axis[2], 'Y', color='cyan', fontsize=12)\n",
    "    ax.text(camera_z_axis[0], camera_z_axis[1], camera_z_axis[2], 'Z', color='magenta', fontsize=12)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImagePixelPoints(ax, image_points, image_width=640, image_height=480):\n",
    "    num_points = len(image_points)\n",
    "    # Pre-generate(fix) colors for consistency\n",
    "    np.random.seed(0)\n",
    "    colors = np.random.rand(num_points, 3)\n",
    "    # Invert y-coordinates for image coordinate system (origin at top-left)\n",
    "    image_points[:, 1] = -image_points[:, 1]\n",
    "    ax.plot([0], [0], marker='x', markersize=10, color='red')\n",
    "    for i in range(num_points):\n",
    "        ax.scatter(image_points[i, 0], image_points[i, 1], c=[colors[i]], marker='o', s=50)\n",
    "        ax.text(image_points[i, 0], image_points[i, 1], f'{i+1}', color='black', fontsize=10)\n",
    "    ax.set_xlabel('U (pixels)')\n",
    "    ax.set_ylabel('V (pixels)')\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{abs(x):0.0f}'))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, pos: f'{abs(y):0.0f}'))\n",
    "    ax.set_xlim(0, image_width)\n",
    "    ax.set_ylim(-image_height, 0)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------\n",
    "### Task-1 Implementation with Interactive 3D Plot\n",
    "### --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT Intrinsic parameters (in pixels)\n",
    "focal_length_x = 800.0 \n",
    "focal_length_y = 700.0\n",
    "principal_point_x = 320.0\n",
    "principal_point_y = 240.0\n",
    "image_width = 640\n",
    "image_height = 480\n",
    "\n",
    "# GT Extrinsic parameters (in degrees and meters)\n",
    "camera_yaw = 3     # small rotation around Y axis\n",
    "camera_pitch = 2   # small rotation around X axis\n",
    "camera_roll = 5    # small rotation around Z axis\n",
    "\n",
    "# Camera translation (in meters)\n",
    "camera_translation_vector_from_world_origin = np.array([2, 2, 12], dtype=np.float32)\n",
    "\n",
    "# Non-coplanar 3D points (provided)\n",
    "world_3D_points = np.array([[1.0, 1.0, 1.0],\n",
    "                            [1.0, 2.0, 2.0],\n",
    "                            [1.0, 3.0, 3.0],\n",
    "                            [2.0, 1.0, 4.0],\n",
    "                            [2.0, 2.0, 5.0],\n",
    "                            [2.0, 3.0, 6.0],\n",
    "                            [2.0, 4.0, 2.5],\n",
    "                            [2.5, 1.0, 8.0],\n",
    "                            [2.5, 2.0, 9.0],\n",
    "                            [2.5, 3.0, 5.5]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create camera rotation matrix from Euler angles\n",
    "camera_rotation_matrix = create_rotation_matrix(camera_yaw, camera_pitch, camera_roll)\n",
    "# Invert X and Z axes for the desired camera coordinate system\n",
    "camera_rotation_matrix[:, 0] = -camera_rotation_matrix[:, 0]\n",
    "camera_rotation_matrix[:, 2] = -camera_rotation_matrix[:, 2]\n",
    "# For world-to-camera transformation, use the transpose\n",
    "R = camera_rotation_matrix.T\n",
    "\n",
    "# Generate the ground truth camera projection matrix and supporting matrices\n",
    "P, RT, K = createGTCameraParameters(focal_length_x, focal_length_y, principal_point_x, principal_point_y, R, camera_translation_vector_from_world_origin)\n",
    "\n",
    "# Project 3D world points to 2D image coordinates\n",
    "camera_pixel_2D_points, insideViewOrNot = project_world_to_camera(world_3D_points, P, image_width, image_height)\n",
    "\n",
    "# Create a figure with two side-by-side subplots\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "# Set initial view angles for the 3D plot\n",
    "initial_elev = 20\n",
    "initial_azim = 45\n",
    "ax1.view_init(elev=initial_elev, azim=initial_azim)\n",
    "\n",
    "# Plot the 3D world points and camera coordinate system\n",
    "plotWorldPoints(ax1, world_3D_points, camera_rotation_matrix, camera_translation_vector_from_world_origin)\n",
    "ax1.set_title('Interactive 3D World Points & Camera Coordinate System', fontsize=14)\n",
    "\n",
    "# Plot the 2D projected image points\n",
    "plotImagePixelPoints(ax2, camera_pixel_2D_points, image_width, image_height)\n",
    "\n",
    "ax2.set_title('2D Projected Points on Image Plane', fontsize=14)\n",
    "\n",
    "# Create an axis for each button in figure coordinates:\n",
    "button_wv = fig.add_axes([0.35, 0.08, 0.12, 0.05])  # x-pos, y-pos, width, height\n",
    "button_cv = fig.add_axes([0.35, 0.02, 0.12, 0.05])\n",
    "\n",
    "world_view_button = Button(button_wv, 'World View')\n",
    "camera_view_button = Button(button_cv, 'Camera View')\n",
    "\n",
    "def reset_world_view(event):\n",
    "    \"\"\"Set the 3D view to 'world view' angles.\"\"\"\n",
    "    ax1.view_init(elev=20, azim=45)  # e.g. for \"world view\"\n",
    "    plt.draw()\n",
    "\n",
    "def reset_camera_view(event):\n",
    "    \"\"\"Set the 3D view to 'camera view' angles.\"\"\"\n",
    "    ax1.view_init(elev=90, azim=90)  # e.g. for \"camera view\"\n",
    "    plt.draw()\n",
    "\n",
    "world_view_button.on_clicked(reset_world_view)\n",
    "camera_view_button.on_clicked(reset_camera_view)\n",
    "\n",
    "# Manually adjust subplot layout instead of tight_layout\n",
    "fig.subplots_adjust(left=0.08, right=0.95, top=0.92, bottom=0.15, wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------\n",
    "### Task-2 Estimating Projection Matrix using DLT Method\n",
    "### --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_projection_matrix(world_points, image_points):\n",
    "    \"\"\"\n",
    "    Estimate the camera projection matrix using the Direct Linear Transform (DLT) algorithm,\n",
    "    and scale it so that the norm of the first three elements of the third row is 1.\n",
    "    \n",
    "    Parameters:\n",
    "      world_points: (N x 3) array of 3D world points.\n",
    "      image_points: (N x 2) array of corresponding 2D image points.\n",
    "      \n",
    "    Returns:\n",
    "      P_estimated: The estimated 3x4 camera projection matrix.\n",
    "    \"\"\"\n",
    "    num_points = world_points.shape[0]\n",
    "    \n",
    "    # Convert world_points to homogeneous coordinates (N x 4)\n",
    "    world_points_hom = np.hstack((world_points, np.ones((num_points, 1))))\n",
    "    \n",
    "    # Ensure image_points are in homogeneous form (N x 3)\n",
    "    image_points_hom = np.hstack((image_points, np.ones((num_points, 1))))\n",
    "    \n",
    "    # Construct the matrix A (2N x 12)\n",
    "    A = []\n",
    "    for i in range(num_points):\n",
    "        X = world_points_hom[i]  # [X, Y, Z, 1]\n",
    "        u, v, _ = image_points_hom[i]  # [u, v, 1]\n",
    "        # First row equation for point i\n",
    "        row1 = np.hstack((-X, np.zeros(4), u * X))\n",
    "        # Second row equation for point i\n",
    "        row2 = np.hstack((np.zeros(4), -X, v * X))\n",
    "        A.append(row1)\n",
    "        A.append(row2)\n",
    "    \n",
    "    A = np.array(A)  # Shape: (2N, 12)\n",
    "    \n",
    "    # Solve A p = 0 using SVD; p is the eigenvector corresponding to the smallest singular value.\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    p = Vt[-1]\n",
    "    \n",
    "    # Reshape p into a 3x4 matrix\n",
    "    P_estimated = p.reshape(3, 4)\n",
    "    \n",
    "    # --- Scaling the Projection Matrix ---\n",
    "    # We want the norm of the first three entries of the third row to be 1.\n",
    "    norm_third_row = np.linalg.norm(P_estimated[2, :3])\n",
    "    scale_factor = 1.0 / norm_third_row\n",
    "    P_estimated = P_estimated * scale_factor\n",
    "    \n",
    "    # --- Optional: Sign Correction ---\n",
    "    # For example, if you expect the last element (P_estimated[2, 3]) to be positive, do:\n",
    "    if P_estimated[2, 3] < 0:\n",
    "        P_estimated = -P_estimated\n",
    "    \n",
    "    return P_estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume world_3D_points and camera_pixel_2D_points are defined from Task-1.\n",
    "# (world_3D_points: (N x 3), camera_pixel_2D_points: (N x 2))\n",
    "\n",
    "P_estimated = find_projection_matrix(world_3D_points, camera_pixel_2D_points)\n",
    "\n",
    "print(\"Estimated Projection Matrix (P_estimated):\")\n",
    "print(P_estimated)\n",
    "\n",
    "print(\"\\nGround Truth Projection Matrix (P):\")\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------\n",
    "### Task-3 Decomposing Estimating Projection Matrix into Intrinsic and Extrinsic Matrices\n",
    "### --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually correct the sign of the estimated projection matrix\n",
    "# Multiply the 2nd row by -1 to correct the sign\n",
    "P_estimated_corrected = P_estimated.copy()\n",
    "P_estimated_corrected[1] = -P_estimated_corrected[1]\n",
    "print(\"Corrected Estimated Projection Matrix (P_estimated_corrected):\")\n",
    "print(P_estimated_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_projection_matrix(P):\n",
    "    \"\"\"\n",
    "    Decomposes a 3x4 projection matrix into intrinsic parameters, rotation, translation, and camera center.\n",
    "    \n",
    "    Parameters:\n",
    "      P : (3x4) numpy array -- the camera projection matrix.\n",
    "      \n",
    "    Returns:\n",
    "      fx, fy, cx, cy : intrinsic parameters.\n",
    "      R             : 3x3 rotation matrix.\n",
    "      t             : translation vector (such that P = K [R | t]).\n",
    "      C             : camera center in world coordinates (C = -R^T t).\n",
    "    \"\"\"\n",
    "    # Partition P into M (first 3 columns) and p4 (last column)\n",
    "    M = P[:, :3]\n",
    "\n",
    "    # Compute the RQ decomposition of M to get K and R\n",
    "    K, R = rq(M)\n",
    "\n",
    "    # Ensure positive diagonal entries for K\n",
    "    T = np.diag(np.sign(np.diag(K)))\n",
    "    \n",
    "    K = K @ T\n",
    "    R = T @ R\n",
    "    \n",
    "    # Normalize K so that K[2,2] == 1\n",
    "    K = K / K[2,2]\n",
    "    \n",
    "    fx = K[0, 0]\n",
    "    fy = K[1, 1]\n",
    "    cx = K[0, 2]\n",
    "    cy = K[1, 2]\n",
    "    \n",
    "    # Compute the translation vector: P = K [R | t] => t = inv(K)*P[:,3]\n",
    "    t = np.linalg.inv(K) @ P[:, 3]\n",
    "    \n",
    "    # Compute camera center: C = -R^T * t   (since t = -R * C)\n",
    "    C = -R.T @ t\n",
    "    \n",
    "    return fx, fy, cx, cy, R, t, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the estimated projection matrix\n",
    "fx_est, fy_est, cx_est, cy_est, R_est, t_est, C_est = decompose_projection_matrix(P_estimated_corrected)\n",
    "\n",
    "# Decompose the ground truth Camera Center\n",
    "print(\"\\nCamera Center C_est:\")\n",
    "print(C_est)\n",
    "# Print Actual Camera Center\n",
    "print(\"Ground Truth Camera Center:\")\n",
    "print(camera_translation_vector_from_world_origin)\n",
    "\n",
    "print(\"\\nTranslation vector t_est:\")\n",
    "print(t_est)\n",
    "# Print Actual Translation Vector\n",
    "print(\"Ground Truth Translation Vector:\")\n",
    "print(RT[:3, 3])\n",
    "\n",
    "print(\"\\nRotation matrix R_est:\")\n",
    "print(R_est)\n",
    "# Print Actual Rotation Matrix\n",
    "print(\"Ground Truth Rotation Matrix:\")\n",
    "print(R)\n",
    "\n",
    "# Construct the estimated K matrix\n",
    "K_est = np.array([[fx_est, 0, cx_est, 0],\n",
    "                  [0, fy_est, cy_est, 0],\n",
    "                  [0, 0, 1, 0]])\n",
    "\n",
    "print(\"\\nEstimated Intrinsic Matrix (K_est):\")\n",
    "print(K_est)\n",
    "# Print Actual Intrinsic Matrix\n",
    "print(\"Ground Truth Intrinsic Matrix (K):\")\n",
    "print(K)\n",
    "\n",
    "# Construct the estimated extrinsic matrix\n",
    "RT_est = np.eye(4)\n",
    "RT_est[:3, :3] = R_est\n",
    "RT_est[:3, 3] = t_est\n",
    "\n",
    "print(\"\\nEstimated Extrinsic Matrix [R_est|t_est]:\")\n",
    "print(RT_est)\n",
    "# Print Actual Extrinsic Matrix\n",
    "print(\"Ground Truth Extrinsic Matrix [R|t]:\")\n",
    "print(RT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Step 1: Project the 3D world points -----\n",
    "projected_points, _ = project_world_to_camera(world_3D_points, P_estimated_corrected, image_width, image_height)\n",
    "\n",
    "# ----- Step 2: Adjust the y-axis sign to match the ground truth -----\n",
    "# Flip the sign of the y-coordinate of the projected points\n",
    "camera_pixel_2D_points[:, 1] = -camera_pixel_2D_points[:, 1]\n",
    "print(\"Ground Truth 2D Points:\")\n",
    "print(camera_pixel_2D_points)\n",
    "\n",
    "# ----- Step 3: Compute the Projection Error -----\n",
    "# Compute the Euclidean distance between each projected point and its corresponding ground truth 2D point.\n",
    "errors = np.linalg.norm(projected_points - camera_pixel_2D_points, axis=1)\n",
    "mean_error = np.mean(errors)\n",
    "print(f\"Mean Projection Error (in pixels): {mean_error:.16f}\")\n",
    "\n",
    "# ----- Step 4: Plot the Ground Truth 2D Points vs. the Projected Points -----\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plot ground truth points (blue circles)\n",
    "plt.scatter(camera_pixel_2D_points[:, 0], camera_pixel_2D_points[:, 1],\n",
    "            color='blue', marker='o', label='Ground Truth 2D Points', s=60)\n",
    "# Plot corrected projected points (red x's)\n",
    "plt.scatter(projected_points[:, 0], projected_points[:, 1],\n",
    "            color='red', marker='x', label='Projected 2D Points (Estimated)', s=60)\n",
    "\n",
    "# Annotate the points by index (optional)\n",
    "for i in range(len(camera_pixel_2D_points)):\n",
    "    plt.text(camera_pixel_2D_points[i, 0] + 2, camera_pixel_2D_points[i, 1] + 2, str(i+1), color='blue', fontsize=9)\n",
    "    plt.text(projected_points[i, 0] + 2, projected_points[i, 1] + 2, str(i+1), color='red', fontsize=9)\n",
    "\n",
    "plt.xlabel('U (pixels)')\n",
    "plt.ylabel('V (pixels)')\n",
    "plt.title('Ground Truth vs. Estimated 2D Projections')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for proper image display\n",
    "plt.grid(True)\n",
    "# Set the full image dimensions for the axes\n",
    "plt.xlim(0, 640)\n",
    "plt.ylim(480, 0)  # Inverted y-axis for proper image display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------\n",
    "### Task-4 Estimating Camera Parameters with the world-points and 2-d points\n",
    "### --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization, print the \"captured\" 2D points\n",
    "print(\"\\nSimulated Captured 2D Points (without noise):\")\n",
    "print(camera_pixel_2D_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add Gaussian noise to simulate errors in detecting marker positions.\n",
    "# Adjusting standard deviation (sigma) to simulate different noise levels.\n",
    "sigma = 5.0  # e.g., 5 pixels standard deviation\n",
    "noise = np.random.normal(0, sigma, camera_pixel_2D_points.shape)\n",
    "camera_pixel_2D_points_noisy = camera_pixel_2D_points + noise\n",
    "\n",
    "print(\"\\nSimulated Captured 2D Points (with noise):\")\n",
    "print(camera_pixel_2D_points_noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_noisy_estimated = find_projection_matrix(world_3D_points, camera_pixel_2D_points_noisy)\n",
    "if P_noisy_estimated[2, 3] < 0:\n",
    "    P_noisy_estimated = -P_noisy_estimated\n",
    "print(\"\\nEstimated Projection Matrix (P_noisy_estimated):\")\n",
    "print(P_noisy_estimated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (You can also decompose P_estimated if needed)\n",
    "fx_est, fy_est, cx_est, cy_est, R_est, t_est, C_est = decompose_projection_matrix(P_noisy_estimated)\n",
    "print(\"\\nEstimated Camera Center (from decomposition):\")\n",
    "print(C_est)\n",
    "print(\"Ground Truth Camera Center:\")\n",
    "print(camera_translation_vector_from_world_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the projection error between the noisy image points and the reprojected points.\n",
    "# (Here, we also invert the y for the noisy points for proper comparison.)\n",
    "noisy_points_display = camera_pixel_2D_points_noisy.copy()\n",
    "errors = np.linalg.norm(projected_points - noisy_points_display, axis=1)\n",
    "mean_error = np.mean(errors)\n",
    "print(f\"\\nMean Projection Error (in pixels): {mean_error:.16f}\")\n",
    "\n",
    "# Plot the results: Ground Truth (noisy \"captured\" points) vs. Reprojected Points from Estimated Matrix.\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(noisy_points_display[:, 0], noisy_points_display[:, 1],\n",
    "            color='blue', marker='o', label='Noisy Captured 2D Points', s=60)\n",
    "plt.scatter(projected_points[:, 0], projected_points[:, 1],\n",
    "            color='red', marker='x', label='Reprojected 2D Points (Estimated)', s=60)\n",
    "for i in range(len(noisy_points_display)):\n",
    "    plt.text(noisy_points_display[i, 0] + 2, noisy_points_display[i, 1] + 2, str(i+1), color='blue', fontsize=9)\n",
    "    plt.text(projected_points[i, 0] + 2, projected_points[i, 1] + 2, str(i+1), color='red', fontsize=9)\n",
    "    \n",
    "plt.xlabel('U (pixels)')\n",
    "plt.ylabel('V (pixels)')\n",
    "plt.title('Comparison: Noisy Captured 2D Points vs. Reprojected 2D Points')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for proper image display\n",
    "plt.grid(True)\n",
    "# Set the full image dimensions for the axes\n",
    "plt.xlim(0, 640)\n",
    "plt.ylim(480, 0)  # Inverted y-axis for proper image display\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
